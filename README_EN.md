## ğŸš€ Project Overview
Based on the `bert-base-chinese` and `chinese-bert-wwm` models from Hugging Face, this project performs Chinese Named Entity Recognition (NER), helping to understand the logic of sequence labeling models and evaluation metrics.  

Implemented modules:
- Data loading and preprocessing (BIO annotation format)
- Model design and training workflow
- Model evaluation and result visualization (visualization using swanlab)
- (New) Supports both `chinese-bert-wwm` and `bert-base-chinese` pre-trained weights, and supports both Weibo_NER and MSRA_NER datasets (can be further extended). Users can select datasets/models via `argparse` arguments or by modifying the `config.json` file.

## âœ… Experimental Results
Evaluation metrics include F1, Precision, and Recall.  
Test results are available on `dev.txt` and `test.txt`.  
See `result/training_log.txt` for details.

## ğŸ“Š Dataset Sources
1. **Weibo NER Dataset**  

    **Description:** This dataset contains a training set (1350), validation set (269), and test set (270). Entity types include geopolitical entities (GPE.NAM), locations (LOC.NAM), organizations (ORG.NAM), persons (PER.NAM), and corresponding nominal references (ending with NOM).  

    **Language:** Chinese  

    **Train/Validation/Test sizes:** 1350/269/270  

    **Number of entity types:** 4  

    **Paper:** [https://aclanthology.org/D15-1064.pdf](https://aclanthology.org/D15-1064.pdf)  

    **Download:** [https://tianchi.aliyun.com/dataset/144312](https://tianchi.aliyun.com/dataset/144312)  

    **GitHub:** [https://github.com/hltcoe/golden-horse](https://github.com/hltcoe/golden-horse)

2. **MSRA NER Dataset**  

    **Description:** The MSRA dataset is a Chinese NER dataset in the news domain. It contains a training set (46364) and a test set (4365). Entity types include locations (LOC), persons (NAME), and organizations (ORG).  

    **Language:** Chinese  

    **Train/Test sizes:** 46364/4365 (I re-split the training set into training and validation sets using `data_split_tools.py`)  

    **Number of entity types:** 3  

    **Paper:** [https://aclanthology.org/W06-0115.pdf](https://aclanthology.org/W06-0115.pdf)  

    **Download:** [https://tianchi.aliyun.com/dataset/144307](https://tianchi.aliyun.com/dataset/144307)  

## ğŸ“‚ Project Structure Example
**Note:** Final trained models and pre-trained model folders are not uploaded.
```
Weibo-NER/
â”œâ”€â”€ model/ 
â”‚ â”œâ”€â”€ models--bert-base-chinese
â”‚ â”œâ”€â”€ models--hfl--chinese-bert-wwm
â”œâ”€â”€ data/ 
â”‚ â”œâ”€â”€ msra_NER
â”‚   â”œâ”€â”€ train.txt #åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ train_split.txt
â”‚   â”œâ”€â”€ dev_split.txt
â”‚   â”œâ”€â”€ test.txt
â”‚   â”œâ”€â”€msra_ner.json
â”‚ â”œâ”€â”€Weibo_NER
â”‚   â”œâ”€â”€ train.txt
â”‚   â”œâ”€â”€ test.txt
â”‚   â”œâ”€â”€ dev.txt
â”‚   â”œâ”€â”€ class.txt
â”œâ”€â”€ result/ #å®éªŒç»“æœ
â”‚ â”œâ”€â”€ bert-base-chineseformsra_NER.pth
â”‚ â”œâ”€â”€ bert-base-chineseforWeibo_NER.pth
â”‚ â”œâ”€â”€ chinese-bert-wwmformsra_NER.pth
â”‚ â”œâ”€â”€ chinese-bert-wwmforWeibo_NER.pth
â”‚ â”œâ”€â”€ training_log.txt
â”‚ 
â”‚â”€â”€ data_process.py
â”‚â”€â”€ model.py
â”‚â”€â”€ train.py
â”‚â”€â”€ predict.py
â”œâ”€â”€ requirements.txt
â”‚â”€â”€ config.json
â”‚â”€â”€ Config.py
â”œâ”€â”€ data_split_tools.py
â”‚â”€â”€ downloadmodel.py
â”‚â”€â”€ tools.py
â””â”€â”€ README.md
â””â”€â”€ README_EN.md
```
